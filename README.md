# i3-papers: Research on Hyper-Efficient LLM Architectures

This repository serves as the central hub for independent research into i3 (Innovative, Intelligent, Inherently Efficient) architectures. Our core mission is to redefine the computational scaling laws for Large Language Models (LLMs) by prioritizing architectural efficiency over brute-force hardware scale, proving that SOTA performance is accessible to all.

# ðŸ“„ Published Research Papers

This section lists the full technical reports available in this repository.

1. The i3-200M Technical Report
>Title: i3-200M: A GRU-Mamba Hybrid Architecture Achieving PPL < 30 in Four Hours on a Single P100
>
>Status: Preprint
>
>Link: [Read the Full Technical Report](papers/i3-200M-112025.pdf)
